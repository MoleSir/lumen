
from typing import List, Tuple, Union, Optional, Sequence, Any, Iterator


Scalar = Union[float, int]
TensorOrScaler = Union[Tensor, Scalar]


def set_grad_enabled(mode: bool) -> None: ...

def is_grad_enabled() -> None: ...

def no_grad(): ...


class DType:
    Float32: "DType"
    Float64: "DType"
    UInt32: "DType"
    Int32: "DType"
    UInt8: "DType"
    Bool: "DType"
    
    def __eq__(self, other: Any) -> bool: ...


class Tensor:
    """
    N-dimensional Tensor library implemented in Rust.
    """

    # ---- factory ----
    
    @staticmethod
    def zeros(shape: Sequence[int], dtype: Optional[DType] = None) -> Tensor:
        ...

    @staticmethod
    def ones(shape: Sequence[int], dtype: Optional[DType] = None) -> Tensor:
        ...

    @staticmethod
    def rand(
        shape: Sequence[int], 
        min: Optional[float] = 0.0, 
        max: Optional[float] = 1.0, 
        dtype: Optional[DType] = None
    ) -> Tensor:
        ...

    @staticmethod
    def randn(
        shape: Sequence[int], 
        mean: Optional[float] = 0.0, 
        std: Optional[float] = 1.0, 
        dtype: Optional[DType] = None
    ) -> Tensor:
        ...

    # ---- attr ----

    def dims(self) -> List[int]:
        ...

    def dtype(self) -> DType:
        ...

    def requires_grad(self) -> bool:
        ...

    def set_requires_grad(self, mode: bool) -> None:
        ...

    # ---- op ----

    def __add__(self, other: TensorOrScaler) -> Tensor: ...
    def __radd__(self, other: TensorOrScaler) -> Tensor: ...

    def __sub__(self, other: TensorOrScaler) -> Tensor: ...
    def __rsub__(self, other: TensorOrScaler) -> Tensor: ...

    def __mul__(self, other: TensorOrScaler) -> Tensor: ...
    def __rmul__(self, other: TensorOrScaler) -> Tensor: ...

    def __truediv__(self, other: TensorOrScaler) -> Tensor: ...
    def __rtruediv__(self, other: TensorOrScaler) -> Tensor: ...
    
    def __div__(self, other: TensorOrScaler) -> Tensor: ... 
    def __rdiv__(self, other: TensorOrScaler) -> Tensor: ...

    def __str__(self) -> str: ...
    def __repr__(self) -> str: ...

    def add(self, other: TensorOrScaler) -> Tensor: ...
    def sub(self, other: TensorOrScaler) -> Tensor: ...
    def mul(self, other: TensorOrScaler) -> Tensor: ...
    def div(self, other: TensorOrScaler) -> Tensor: ...

    def eq(self, other: TensorOrScaler) -> Tensor: ...
    def ne(self, other: TensorOrScaler) -> Tensor: ...
    def ge(self, other: TensorOrScaler) -> Tensor: ...
    def le(self, other: TensorOrScaler) -> Tensor: ...
    def gt(self, other: TensorOrScaler) -> Tensor: ...
    def lt(self, other: TensorOrScaler) -> Tensor: ...

    def floor(self) -> Tensor: ...
    def ceil(self) -> Tensor: ...
    def round(self) -> Tensor: ...
    def abs(self) -> Tensor: ...
    def recip(self) -> Tensor: ...  
    def sqr(self) -> Tensor: ... 

    def exp(self) -> Tensor: ...
    def ln(self) -> Tensor: ...
    def sin(self) -> Tensor: ...
    def cos(self) -> Tensor: ...
    def tanh(self) -> Tensor: ...
    def sqrt(self) -> Tensor: ...
    def erf(self) -> Tensor: ...

    def gelu(self) -> Tensor: ...
    def gelu_erf(self) -> Tensor: ...
    def relu(self) -> Tensor: ...
    def silu(self) -> Tensor: ...
    def sigmoid(self) -> Tensor: ...

    def __matmul__(self, other: Tensor) -> Tensor: ...

    def __rmatmul__(self, other: Tensor) -> Tensor: ...

    def matmul(self, rhs: Tensor) -> Tensor: ...

    def neg(sef) -> Tensor: ...

    # ---- reductions ----

    def sum(self, dim: Optional[int] = None, keep_dim: bool = False) -> Tensor: ...

    def min(self, dim: Optional[int] = None, keep_dim: bool = False) -> Tensor: ...

    def max(self, dim: Optional[int] = None, keep_dim: bool = False) -> Tensor: ...

    def mean(self, dim: Optional[int] = None, keep_dim: bool = False) -> Tensor: ...

    def var(self, dim: Optional[int] = None, keep_dim: bool = False, unbiased: bool = True) -> Tensor: ...

    # ---- comparison ----

    def allclose(self, other: Tensor, rtol: float=1e-5, atol: float=1e-8) -> bool: ...

    # ---- shape ops ----

    def squeeze(self, dim: int) -> Tensor: ...

    def unsqueeze(self, dim: int) -> Tensor: ...

    def narrow(self, dim: int, start: int, length: int) -> Tensor: ...

    def slice(self, dim: int, slice: slice) -> Tensor: ...

    def reshape(self, shape: Sequence[int]) -> Tensor: ...

    def transpose(self, dim1: int, dim2: int) -> Tensor: ...

    def permute(self, dims: Sequence[int]) -> Tensor: ...

    def flatten(self, start_dim: int, end_dim: int) -> Tensor: ...

    def flatten_all(self) -> Tensor: ...

    def repeat_dim(self, dim: int, times: int) -> Tensor: ...

    def broadcast_as(self, shape: Sequence[int]) -> Tensor: ...

    # ---- concat / split ----

    @staticmethod
    def cat(tensors: Sequence[Tensor], dim: int) -> Tensor: ...

    @staticmethod
    def stack(tensors: Sequence[Tensor], dim: int) -> Tensor: ...

    def split(self, dim: int) -> List[Tensor]: ...

    def chunk(self, chunks: int, dim: int) -> List[Tensor]: ...

    # ---- autograd ----

    def backward(self) -> GradStore: ...


class GradStore:
    def __getitem__(self, index: int) -> Tensor: ...

    def items(self) -> Iterator[Tuple[int, Tensor]]: ...
    def keys(self) -> Iterator[int]: ...
    def values(self) -> Iterator[Tensor]: ...

    def __iter__(self) -> Iterator[int]: ...

    def __len__(self) -> int: ...
